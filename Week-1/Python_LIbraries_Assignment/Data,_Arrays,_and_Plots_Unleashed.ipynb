{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ryA0MnbSdY4"
   },
   "source": [
    "# Assignment on Python Libraries\n",
    "*   The dataset for this assignment is provided in the same folder as the assignment.\n"
    "*   Try to write optimal code for each section and explain your understanding wherever required.\n",
    "*  Required Libraries are imported wherever needed.\n",
    "*   It's suggested to do it after studying all topics to reinforce your learning. Just a reminder, this assignment can be done in 10min using A.I, which will increase your skill of chatting with chatgpt (**but nothing else**), so try to approach with a bit more purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mLfd3EuXkZlv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cH7BERQ0w5u9"
   },
   "source": [
    "### Read the csv and store it in a dataframe named mobile_usage\n",
    "*  Identify the null values in the dataframe and print the count of null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-XnadFVwFBt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj8bDQKMxVOz"
   },
   "source": [
    "#Identify Different dtypes of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aeZzfLZgwr9C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN_PjMEdxfmG"
   },
   "source": [
    "#Get the count of number of people of each age  in the dataset and store it in a 2-d numpy array with first element in row being age and second element number of people with that age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dosxvzfUzYfu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bajcSD-xzZlI"
   },
   "source": [
    "#Calculate the average usage_time for different age groups and identify the age group with the highest total usage_time (screen time).\n",
    "#Plot graphs of average usage_time versus age:\n",
    "* Scatter plot\n",
    "* Bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvC5re5x0vMQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7axJDBB_iRj"
   },
   "source": [
    "#Sort the DataFrame by age using both Pandas and NumPy.\n",
    "* Remove the data of individuals above 45 years of age and  store the modified DataFrame in a new variable new_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBv7ATtAh6Ai"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGubnDPHrzXX"
   },
   "source": [
    "### Add a New Column **location_type**\n",
    "*  Create a new column named location_type in the original DataFrame (mobile_usage).\n",
    "*  Assign integer labels to locations based on their frequency (in descending order):\n",
    " *  The most frequent location should be labeled as 0.\n",
    " *  The second most frequent location should be labeled as 1, and so on.\n",
    " *  Less frequent locations will have higher integer values.\n",
    "*  Ensure that the labels are assigned based strictly on the frequency ranking of the locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rssG8ShPbVE1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK5EdTHtelTN"
   },
   "source": [
    "### Normalisation\n",
    " Normalization is a process used to adjust the scale or range of data values, making them consistent and comparable across different features or datasets. It ensures that all features contribute equally to a model or analysis, especially when they have vastly different scales.\n",
    "\n",
    " Just understand the definition for now , in the upcoming weeks this topic will be discussed in detail.\n",
    "\n",
    "*  Normalize the gaming app usage hours using min-max scaling (https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)) and store it in some numpy array .\n",
    "*  Verify whether the normalisation correct or not by plotting histograms with same name number of bins(Why?Is it correct?) .\n",
    "*  (Optional) Write a function which takes argument a dataframe and returns a dataframe which have all columns in its **Normalized** by min - max scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9Yxh3T5fIrU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3Y9C9dmjiSp"
   },
   "source": [
    "### Plot the relationship between Number_of_apps_used and Daily_Screen_Time_Hours using different types of plots (e.g., scatter plot, line plot, bar graph, etc.).\n",
    "* Analyze the plots and explain which type of plot best illustrates the relationship between these two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WvuVS_qnb8F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSnpJVHHA17o"
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_AnkScWnhH7"
   },
   "source": [
    "# Broadcasting\n",
    "\n",
    "*  Use multiple columns from a DataFrame to represent points in an n-dimensional space (take atleast 3 columns).\n",
    "*  Calculate the Euclidean distance between all pairs of points using:\n",
    "* A loop-based approach (without broadcasting).\n",
    "* A vectorized approach using broadcasting.\n",
    "* Compare the results and performance of both methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGVoYNRhKCow"
   },
   "source": [
    "### To compare the performances use the time module\n",
    "\n",
    " A sample code is given below .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiPhB_IenjZK"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# # Timing the loop-based approach\n",
    "# start_time = time.time()\n",
    "# # (Loop-based distance calculation code here)\n",
    "# end_time = time.time()\n",
    "# print(f\"Loop-based method took {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# # Timing the broadcasting approach\n",
    "# start_time = time.time()\n",
    "# # (Broadcasting-based distance calculation code here)\n",
    "# end_time = time.time()\n",
    "# print(f\"Broadcasting method took {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymsGVPdRX9QB"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# write your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
